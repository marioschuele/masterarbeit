{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marioschuele/masterarbeit/blob/main/SOTA_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-16T08:09:44.117287Z",
          "iopub.status.busy": "2023-03-16T08:09:44.116964Z",
          "iopub.status.idle": "2023-03-16T08:09:50.210051Z",
          "shell.execute_reply": "2023-03-16T08:09:50.208907Z",
          "shell.execute_reply.started": "2023-03-16T08:09:44.117267Z"
        },
        "id": "oyXK1IHJTJvM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1v8_DVqThpN",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Install package Kaggle for dataset download\n",
        "! pip install kaggle -q\n",
        "\n",
        "#Download and unzip Kaggle dataset\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download yuweisunut/sidd-segmented-intrusion-detection-dataset\n",
        "!unzip sidd-segmented-intrusion-detection-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-16T08:09:50.213712Z",
          "iopub.status.busy": "2023-03-16T08:09:50.212369Z",
          "iopub.status.idle": "2023-03-16T08:10:17.477789Z",
          "shell.execute_reply": "2023-03-16T08:10:17.476674Z",
          "shell.execute_reply.started": "2023-03-16T08:09:50.213679Z"
        },
        "id": "GdJxhSGqYIK2"
      },
      "outputs": [],
      "source": [
        "directory = 'SIDD'\n",
        "\n",
        "imgs = {}\n",
        "uid = 0\n",
        "\n",
        "for client in os.listdir(directory):\n",
        "  curr_path = f'{directory}/{client}/pcap'\n",
        "\n",
        "  for subdir in os.listdir(curr_path):\n",
        "    curr_path = f'{directory}/{client}/pcap/{subdir}/dataset'\n",
        "    curr_type = subdir[-1:]\n",
        "    if curr_type == str(1):\n",
        "        \n",
        "        for dayscen in os.listdir(curr_path):\n",
        "          curr_path = f'{directory}/{client}/pcap/{subdir}/dataset/{dayscen}'\n",
        "\n",
        "          for img in os.listdir(curr_path):\n",
        "            if dayscen == 'benign':\n",
        "                imgs[uid] = {'id': uid, 'label': str(0), 'fn': img, 'path': curr_path + '/' + img}\n",
        "            elif dayscen == 'malicious':\n",
        "                imgs[uid] = {'id': uid, 'label': str(curr_type), 'fn': img, 'path': curr_path + '/' + img}\n",
        "            uid +=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-16T08:10:17.480213Z",
          "iopub.status.busy": "2023-03-16T08:10:17.479874Z",
          "iopub.status.idle": "2023-03-16T08:10:18.784351Z",
          "shell.execute_reply": "2023-03-16T08:10:18.783394Z",
          "shell.execute_reply.started": "2023-03-16T08:10:17.480181Z"
        },
        "id": "_LImBC0Fd44n"
      },
      "outputs": [],
      "source": [
        "img_df = pd.DataFrame.from_dict(imgs,orient='index')\n",
        "img_df['label'] = img_df['label'].astype(int)\n",
        "#img_df.loc[img_df.index[(img_df['label']==3)],'label'] = 2\n",
        "print(len(img_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-16T08:10:18.785747Z",
          "iopub.status.busy": "2023-03-16T08:10:18.785463Z",
          "iopub.status.idle": "2023-03-16T08:10:21.115575Z",
          "shell.execute_reply": "2023-03-16T08:10:21.114929Z",
          "shell.execute_reply.started": "2023-03-16T08:10:18.785720Z"
        },
        "id": "pOXjJ1yUWisg"
      },
      "outputs": [],
      "source": [
        "def _parse_function(filename, label):\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.cast(image_decoded, tf.float32)\n",
        "    return image, label\n",
        "\n",
        "file_paths = img_df.path\n",
        "file_labels = img_df[\"label\"]\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((file_paths, file_labels))\n",
        "\n",
        "dataset = dataset.map(_parse_function)\n",
        "dataset = dataset.batch(32)\n",
        "dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-16T08:10:23.078773Z",
          "iopub.status.busy": "2023-03-16T08:10:23.077713Z",
          "iopub.status.idle": "2023-03-16T08:10:23.105912Z",
          "shell.execute_reply": "2023-03-16T08:10:23.105315Z",
          "shell.execute_reply.started": "2023-03-16T08:10:23.078738Z"
        },
        "id": "nIwxu1-st_Xr"
      },
      "outputs": [],
      "source": [
        "#Distribute dataset into train, validation and test set\n",
        "def get_dataset_partitions_tf(ds, ds_size, train_split, val_split, test_split, shuffle, shuffle_size):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "        prefetch_size = tf.data.AUTOTUNE\n",
        "        ds = ds.prefetch(prefetch_size)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "\n",
        "    print('Size of {}:  {}'.format('train ds', str(train_ds.cardinality().numpy())))\n",
        "    print('Size of {}:  {}'.format('val ds', str(val_ds.cardinality().numpy())))\n",
        "    print('Size of {}:  {}'.format('test ds', str(test_ds.cardinality().numpy())))\n",
        "    \n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(ds=dataset, ds_size=dataset.cardinality().numpy(), train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-15T19:09:41.992802Z",
          "iopub.status.busy": "2023-03-15T19:09:41.992281Z",
          "iopub.status.idle": "2023-03-15T20:09:05.391748Z",
          "shell.execute_reply": "2023-03-15T20:09:05.391009Z",
          "shell.execute_reply.started": "2023-03-15T19:09:41.992781Z"
        },
        "id": "ByPsAlobUqyo",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Create a TensorBoard callback\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "model = tf.keras.applications.EfficientNetB3(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=2,\n",
        "    classifier_activation=\"sigmoid\"\n",
        ")\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(),  #learning_rate = 0.01\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']        #keras.metrics.sparse_categorical_accuracy\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")\n",
        "\n",
        "evaluation = model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEQeBSx_kV04"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-15T20:22:23.162617Z",
          "iopub.status.busy": "2023-03-15T20:22:23.162104Z",
          "iopub.status.idle": "2023-03-15T20:22:23.410452Z",
          "shell.execute_reply": "2023-03-15T20:22:23.409850Z",
          "shell.execute_reply.started": "2023-03-15T20:22:23.162594Z"
        },
        "id": "gL_bU9kaLWa4"
      },
      "outputs": [],
      "source": [
        "#Plot accuracy of model\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#Plot loss of model\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}